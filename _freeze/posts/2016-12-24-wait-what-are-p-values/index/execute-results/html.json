{
  "hash": "0430e436b47960d8a82045e61a930b05",
  "result": {
    "markdown": "---\nauthor: \"Nick Strayer\"\ndate: 2016-12-24T15:50:12-06:00\ndescription: \"P-Values are annoying, let's understand them so we dont get beaten by them.\"\ntitle: \"Wait, what are P-values?\"\n---\n\n\n\n\nFrequently, and especially [recently](http://www.nytimes.com/2016/11/09/podcasts/election-analysis-run-up.html), misunderstandings of common statistical terms/ concepts have caused confusion and even [anger](http://www.theverge.com/2016/11/8/13571216/new-york-times-election-forecast-jitter-needle). I would like to (attempt) to clear up a big player in the world of commonly used (and commonly misunderstood) statistical concepts: the __*p*-value__.  \n\n<p style = \"font-size: 7; font-style:italic\">\n  <a href = \"http://imgs.xkcd.com/comics/p_values.png\">\n    <img style=\"width:40%\" src=\"http://imgs.xkcd.com/comics/p_values.png\" align=\"middle\"> \n  </a> </br>\n  Stealing <a href = \"https://twitter.com/LucyStats\">Lucy D'Agostino McGowan's</a> <a href = \"http://xkcd.com\">XKCD</a> embedding strategy. \n</p>\n\n##TL DR\n\nA _p_-value is not a probability of the true parameter being something, but the percentage of times that the data you saw, or more extreme data, would occur given some \"null\" model. These are subtly, but importantly, different concepts. \n\n\n## Setup: \n\nWe will illustrate this concept with a story. \n\nSay you are a cheating detection analyst at a casino. One day one of the casino's employees comes up to you and tells you that there potentially are unfair coins being used in the casino (they seem to land on tails more frequently). It's your job to figure out if they are fair or not. The employee hands you a piece of paper with something written on it and then runs away to attend to more important things than statistics. The paper says the following: \n\n> Heads = $h$, Tails = $t$ | $t,t,h,t,t,h$\n\nAfter staring at this paper for a few minutes, you decide what you have is data on which face of a coin landed upright on a given flip, for a total of 6 flips. A fair coin in your opinion is one that has the same chance of falling on heads as it does tails, or 50-50. This is your __null hypothesis: $P(\\text{tails}) = 0.5$__.  The employee said they thought the coins were biased towards tails, you want to test if they are, this is your __alternative hypothesis: $P(\\text{tails}) > 0.5$__. Your job as a statistician is to take this incredibly complex data and distill it to a single decision, the coin is fair (null), or the coin is biased towards tails (alternative). \n\n<p style = \"font-size: 4; font-style:italic\">\n\n  <img  style=\"width:60%\"  src=\"http://i.onionstatic.com/avclub/5621/63/animated/original.gif\" align=\"middle\"> \n  </br> \n  <a href = \"http://i.onionstatic.com/avclub/5621/63/animated/original.gif\">Fox Sports</a>. \n</p>\n\n## Procedure \n\nYou have a problem: you don't even know how to find an unfair coin (or how unfair of a coin to find). You do, however, have a normal quarter in your back pocket (that you're sure is fair). You decide that instead of getting up and finding a tail-biased coin, you can use your quarter to test if the data you have is _not_ from a fair coin. (You also enjoy injecting negatives into your statements to obfuscate your point as much as possible.) \n\nYou roll over to your coin flipping table, get out your laptop and flip your quarter 6 times. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#Write down coin flip results\nflip_data <-  data_frame(flip = c(\"tails\", \"tails\", \"heads\", \"heads\", \"tails\", \"tails\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n```\n:::\n\n```{.r .cell-code}\n#Plot the coin flips. \n#Code for plot_flips() is at the end of this document (it's ugly)\nflip_data %>% plot_flips()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nOkay, so we got __2__ heads on our __6__ flips. Obviously the data given to us is from an unfair coin. You're a good [frequentist](https://en.wikipedia.org/wiki/Frequentist_inference) however, so you decide that, to be safe, you should repeat the experiment again to see what you get. \n\n_Oh no, you dropped your coin, better use R instead._\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#Function to flip our coin 6 times\nflip_coin <- function(numberOfCoins = 6, probHeads = 0.5){\n  heads <- runif(numberOfCoins) > probHeads\n  return(data_frame(flip = ifelse(heads, \"heads\", \"tails\")))\n}\n\n#flip our virtual coin 6 times\nsecond_flip <- flip_coin()\n\n#plot it\nsecond_flip %>% plot_flips()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nOh look at that... 2 heads... that's nice, but maybe we should do this a few more times. Maybe 100?\n\nBack to R...\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#Dataframe to hold our coin flips\nflip_results <- data_frame(flip = character(), trial = numeric())\n\n#Number of trials of flipping our coin 6 times we want to do. \nnumber_of_trials <- 100\n\n#Actually run the trials \nfor(trial_number in 1:number_of_trials){\n  \n  #Flip Coin 6 times and record results along with trial number\n  flips <- flip_coin() %>%\n    mutate(trial = trial_number)\n  \n  #Append this to our big results dataframe\n  flip_results <- flip_results %>% bind_rows(flips)\n}\n\n#Let's plot all of these results into one big mega-graph\nflip_results %>% \n  plot_flips() + \n  facet_wrap(~trial) + #make a new mini plot for each trial\n  labs(title = \"Six Coin Flips | 100 Trials\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=960}\n:::\n:::\n\n\nWell look at that, investigating this plot it doesn't actually seem that out of the ordinary to get 4 tails in 6 flips, even though intuitively that sounds like tails happening twice as often as heads. \n\nJust to make sure lets simplify the above plot to summarize the number of tails we saw for each of our 100 trials. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#Count how many tails we got in each trial\ntails_by_trial <- flip_results %>%   #Take our results\n  filter(flip == \"tails\") %>%        #Look at only tails results\n  group_by(trial) %>%                #Collapse per trial\n  summarise(number_of_tails = n())   #Count the number of heads per trial\n\n#Look at the first few of our results....\ntails_by_trial %>% \n  head() %>% \n  kable(align = c(\"r\", \"c\"))\n```\n\n::: {.cell-output-display}\n| trial| number_of_tails |\n|-----:|:---------------:|\n|     1|        5        |\n|     2|        3        |\n|     3|        4        |\n|     4|        3        |\n|     5|        4        |\n|     6|        3        |\n:::\n:::\n\n\nLooking at the first few results we can see that we have a range of tails counts, looking at tables is boring though. Let's plot our data to really see what's going on. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntails_by_trial %>%\n  mutate(`bias to tails` = ifelse(number_of_tails >= 4, \"equal or more \", \"less than observed data\")) %>% \n  ggplot(aes(x = number_of_tails, fill = `bias to tails`)) + \n  geom_bar() + \n  labs(title = \"Number of Tails Seen in 6 Flips\", \n       subtitle = \"100 Trials\", x = \"# of tails\", y = \"times seen\") + \n  scale_x_continuous(breaks = 0:6) +               #Beyond here is unneccesary ggplot style stuff. \n  theme_minimal() +                                #I like pretty graphs\n  theme(panel.grid.major.x = element_blank(),\n        panel.grid.major.y = element_line( size=.1, color=\"black\" ),\n        panel.grid.minor = element_blank(),\n        legend.position = \"top\") + \n  scale_fill_discrete(guide = guide_legend(reverse=T))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The `size` argument of `element_line()` is deprecated as of\nggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe data we have: __4__ tails out of __6__ flips, looks pretty darn normal if our coin was fair. Case closed, right? Well you are a statistician so it's your job to distill this down to a number, so let's see exactly how \"normal\" our result is. We will do this by simply counting. Looking at the 100 trials that we did, how many times did the number of tails look at least as unfair as our data? Aka, how many times did we flip 4 or more tails in our 100 trials?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunusualness <- sum(tails_by_trial$number_of_tails >= 4) \nunusualness\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 31\n```\n:::\n:::\n\n\nSo, we have just shown that, given the coin is truly fair, in 100 trials we saw 31 of them to be as \"biased\" towards tails as the data we were given. $$\\frac{31}{100} = 0.31= \\boxed{\\text{our p-value}}$$ \n\nNote that this is not \"the probability that our coin is not fair\", it is simply, \"given the coin _was fair_, how odd are our results?\"\n\n_Note: This is not actually how most p-value are calculated. This is because when lots of this p-value stuff was developed we didn't have computers around to do our coin-flipping-bidding so smart people come up with mathematical formulas that describe the behavior, thus allowing p-values to be calculated with pen and paper. These formulas are also more accurate than what we did in that they mimic flipping the coin an infinite amount of times._\n\n\n<p style = \"font-size: 4; font-style:italic\">\n\n  <img  style=\"width:60%\" src=\"http://starecat.com/content/wp-content/uploads/dog-calculating-how-to-carry-a-stick-on-a-bridge.gif\" align=\"middle\"> \n  </br> \n  Me trying to understand p-values for the first time: <a href = \"http://starecat.com/content/wp-content/uploads/dog-calculating-how-to-carry-a-stick-on-a-bridge.gif\">starecat.com</a>. \n</p>\n\n\n\n\n## The Caveat\n\nBut wait, you can't leave just yet. We made one very important assumption in constructing this _p_-value. We assumed the \"model\" that our data came from. In this case we assumed that the \"heads\" and \"tails\" written on the page were from a single coin, flipped 6 times with two possible results (\"heads\" or \"tails\"). What if it wasn't the case? What if in fact our data came from a mysterious 3 sided coin (all coins technically are). Then our p-value is totally wrong. \n\nSomething to always be aware of when looking at statistical results is that, to quote statistician George Box, \n\n> All models are wrong, but some are useful. \n\nAlmost never in real life are the _p_-values you see in the newspaper or a scientific journal article using the perfectly correct model. Lots of work has been done to make sure that we're not making huge mistakes (or else statisticians like me would be out of a job), but very rarely (even in the example just given) are we using the correct model to generate our _p_-value. \n\n\n## Addendum\n\nI most likely made some mistakes somewhere in this article. If you catch them and feel them important enough to be fixed send me a message on twitter or if you are feeling particularly altruistic, submit a pull request on the repo for this article \n\nHere is the plotting code I used for the head tails plots. It's kind of ugly and I'm sure there's a more elegant way to code it. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.eval .cell-code}\n#Function for plotting coin flips. \n#Takes a dataframe with at least the column \"flip\" containing heads or tails in character value\nplot_flips <- function(flip_data){\n  flip_data %>% \n    mutate(value = 1, flip_num = 1:dim(flip_data)[1]) %>% \n    ggplot(aes(x = flip, y = value, group = flip_num, fill = flip)) +\n    geom_bar(position = \"stack\", stat = \"identity\", color = \"white\") +\n    labs(x = \"\", y = \"times seen\", title = \"Six Coin Flips\") +\n    theme_minimal() + \n    theme(panel.grid.major = element_blank(),\n          panel.grid.minor = element_blank(),\n          strip.background = element_blank(),\n          strip.text = element_blank(),\n          axis.title = element_blank(),\n          axis.text = element_blank(),\n          axis.ticks = element_blank(),\n          legend.position = \"bottom\",\n          legend.title = element_blank()) \n}\n```\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}