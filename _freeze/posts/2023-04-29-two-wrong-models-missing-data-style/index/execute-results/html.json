{
  "hash": "a5adcf991b665659d3fb471000221885",
  "result": {
    "markdown": "---\ntitle: \"Are two wrong models better than one? Missing data style\"\nauthor: Lucy D'Agostino McGowan\ndate: '2023-04-29'\ncategories: [\"rstats\", \"simulations\", \"missing data\"]\ndescription: \"Would imputing + fitting an outcome model using the wrong variables be better than just fitting the wrong outcome model? Let's investigate!\"\n---\n\n\n\nAfter my [previous post about missing data](https://livefreeordichotomize.com/posts/2023-04-28-imputation-might-be-silly/), Kathy [asked on Twitter](https://twitter.com/CausalKathy/status/1652138888100470785?s=20) whether two wrong models (the imputation model + the outcome model) would be better than one (the outcome model alone).\n\n> Without doing any of the math, I'd guess the assumption of correctly spec the model also has a bigger impact in the CC analysis.\n\n> You need correct spec in MI, twice, but trade off that potential bias for higher prec.\n\nThis is a great question! I am going to investigate via a small simulation (so the answer could be \"it depends\", but at least we will know how it seems to work in this very simple case) ðŸ˜†.\n\nOk so here I have some predictor, `x` that is missing 50% of the time, dependent on `c_x` and `c_y`. The right imputation model would have `c_x`, the right outcome model needs `c_y`. Unfortunately, we only have access to one, which we will try to use in our imputation model (and outcome model). Let's see whether two (wrong) models are better than one!\n\nA \"correct\" model will be one that estimates that the coefficient for `x` is 1. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(mice)\n\nn <- 1000\n\nset.seed(928)\n\ndata <- tibble(\n  c_x = rnorm(n, sd = 0.71),\n  x = c_x + rnorm(n, sd = 0.71),\n  c_y = rnorm(n),\n  y = x + c_y + rnorm(n),\n  noise = rnorm(n),\n  x_miss = rbinom(n, 1, 1 / (1 + exp(-(c_x + c_y)))),\n  x_obs = ifelse(\n    x_miss,\n    NA,\n    x\n  )\n)\n```\n:::\n\n\n## We only have `c_x`\n\nOk first let's look at the whole dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_full_c_x <- lm(y ~ x + c_x, data = data) |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_full_c_x\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 3\n  estimate conf.low conf.high\n     <dbl>    <dbl>     <dbl>\n1     1.01    0.877      1.14\n```\n\n\n:::\n:::\n\n\nThis checks out! `c_x` basically does nothing for us here, but because `c_y` is not actually a confounder (it just informs the missingness & `y`, which we aren't observing here), we are just fine estimating our \"wrong\" model in the fully observed data. Now let's do the \"complete cases\" analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_cc <- na.omit(data)\nmod_cc_c_x <- lm(y ~ x + c_x, data = data_cc) |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_cc_c_x\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 3\n  estimate conf.low conf.high\n     <dbl>    <dbl>     <dbl>\n1    0.999    0.812      1.19\n```\n\n\n:::\n:::\n\nThis does fine! Now let's do some imputation. I am going to use the `mice` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_data_c_x <- mice(\n  data, \n  m = 5, \n  method = \"norm.predict\",\n  formulas = list(x_obs ~ c_x),\n  print = FALSE)\n```\n:::\n\n\nOk let's compare how this model does \"alone\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_imp_c_x <- with(imp_data_c_x, lm(y ~ x_obs)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_imp_c_x\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  estimate  conf.low conf.high\n1 1.026666 0.9042858  1.149046\n```\n\n\n:::\n:::\n\n\nGreat! This was the right model, so we would expect this to perform well.\n\nNow what happens if we adjust for `c_x` in addition in the outcome model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_double_c_x <- with(imp_data_c_x, lm(y ~ x_obs + c_x)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_double_c_x\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate  conf.low conf.high\n1 0.9991868 0.7968509  1.201523\n```\n\n\n:::\n:::\n\nThe right imputation model with the wrong outcome model is fine!\n\n## We only have `c_y`\n\nOk first let's look at the whole dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_full_c_y <- lm(y ~ x + c_y, data = data) |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_full_c_y\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 3\n  estimate conf.low conf.high\n     <dbl>    <dbl>     <dbl>\n1     1.01    0.946      1.08\n```\n\n\n:::\n:::\n\n\nLooks good! Now let's do the \"complete cases\" analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_cc_c_y <- lm(y ~ x + c_y, data = data_cc) |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_cc_c_y\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 3\n  estimate conf.low conf.high\n     <dbl>    <dbl>     <dbl>\n1     1.01    0.909      1.11\n```\n\n\n:::\n:::\n\n\nGreat! It works. This shows that as long as we have the right outcome model we can do complete case analysis even if the data is missing not at random (cool!). Now let's do some imputation. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_data_c_y <- mice(\n  data, \n  m = 5, \n  method = \"norm.predict\",\n  formulas = list(x_obs ~ c_y),\n  print = FALSE)\n```\n:::\n\n\nOk let's compare how this model does \"alone\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_imp_c_y <- with(imp_data_c_y,lm(y ~ x_obs)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_imp_c_y\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate conf.low conf.high\n1 0.6888255 0.527796  0.849855\n```\n\n\n:::\n:::\n\n\nOh no, very bad! The wrong imputation model is worse than complete case! By a lot! This estimate is off by 0.31. Does conditioning on `c_y` help us at all?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_double_c_y <-  with(imp_data_c_y, lm(y ~ x_obs + c_y)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_double_c_y\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  estimate  conf.low conf.high\n1 1.009655 0.8887281  1.130582\n```\n\n\n:::\n:::\n\n\nPhew, the wrong imputation model with the wrong outcome model is back to being fine.\n\n## What if both are wrong?\n\nOk, what if we just had our useless variable, `noise`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_full_noise <- lm(y ~ x + noise, data = data) |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_full_noise\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 3\n  estimate conf.low conf.high\n     <dbl>    <dbl>     <dbl>\n1    0.992    0.898      1.09\n```\n\n\n:::\n:::\n\nThis is fine! `c_x` and `c_y` aren't confoudners so we can estimate the coefficent for `x` without them -- `noise` doesn't do anything, but it also doesn't hurt. What about complete case?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_cc_noise <- lm(y ~ x + noise, data = data_cc) |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_cc_noise\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 3\n  estimate conf.low conf.high\n     <dbl>    <dbl>     <dbl>\n1    0.887    0.748      1.03\n```\n\n\n:::\n:::\n\n\nOops! We've got bias (as expected!) -- we end up with a biased estimate by ~0.11.\n\nWhat if we build the (wrong) imputation model?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_data_noise <- mice(\n  data, \n  m = 5, \n  method = \"norm.predict\",\n  formulas = list(x_obs ~ noise),\n  print = FALSE) \n```\n:::\n\n\nOk let's compare how this model does \"alone\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_imp_noise <-  with(imp_data_noise, lm(y ~ x_obs)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_imp_noise\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate  conf.low conf.high\n1 0.8807755 0.7217368  1.039814\n```\n\n\n:::\n:::\n\n\nThis is also wrong (womp womp!) What if we try two wrong models?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_double_noise <-  with(imp_data_noise,lm(y ~ x_obs + noise)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_double_noise\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate  conf.low conf.high\n1 0.8865363 0.7275635  1.045509\n```\n\n\n:::\n:::\n\n\nNope ðŸ˜¢. Two wrong models here are not better than one! It's worse! Womp womp. \n\nLet's put these all together:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_rows(\n  mod_full_c_x,\n  mod_full_c_y,\n  mod_full_noise,\n  mod_cc_c_x,\n  mod_cc_c_y,\n  mod_cc_noise,\n  mod_imp_c_x,\n  mod_imp_c_y,\n  mod_imp_noise,\n  mod_double_c_x,\n  mod_double_c_y,\n  mod_double_noise\n) |>\n  mutate(\n    mod = factor(c(\"Full data with c_x\", \n                   \"Full data with c_y\", \n                   \"Full data with noise\",\n                   \"Complete case with c_x\",\n                   \"Complete case wtih c_y\",\n                   \"Complete case with noise\",\n                   \"Imputation with c_x\",\n                   \"Imputation with c_y\",\n                   \"Imputation with noise\",\n                   \"Two models with c_x\",\n                   \"Two models with c_y\",\n                   \"Two models with noise\" ),\n                 levels = c(\"Full data with c_x\", \n                            \"Complete case with c_x\",\n                            \"Imputation with c_x\",\n                            \"Two models with c_x\",\n                            \"Full data with c_y\", \n                            \"Complete case wtih c_y\",\n                            \"Imputation with c_y\",\n                            \"Two models with c_y\",\n                            \"Full data with noise\",\n                            \"Complete case with noise\",\n                            \"Imputation with noise\",\n                            \"Two models with noise\" )),\n    mod = fct_rev(mod),\n  ) -> to_plot\n\nggplot(to_plot, aes(x = estimate, xmin = conf.low, xmax = conf.high, y = mod)) +\n  geom_pointrange() + \n  geom_vline(xintercept = 1, lty = 2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nSo there you have it, two wrong models are rarely better than one.\n\n## Addendum!\n\nIn writing this post, I found that I was getting biased results when I was correctly specifying my imputation model when using the `{mice}` defaults (which is why the code above specifies `norm.predict` for the method, forcing it to use linear regression, as the data were generated). I didn't understand why this is happening until some helpful friends on Twitter explained it (thank you [Rebecca](https://twitter.com/rrandridge), [Julian](https://twitter.com/DrJWolfson), and [Mario](https://twitter.com/mariokeko1995/). I'll show you what is happening and then I'll show a quick explanation. Let's try to redo the imputation models using the defaults:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_default_c_x <- mice(\n  data, \n  m = 5, \n  formulas = list(x_obs ~ c_x),\n  print = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_imp_c_x <- with(imp_default_c_x, lm(y ~ x_obs)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_imp_c_x\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate  conf.low conf.high\n1 0.7353276 0.6194273 0.8512279\n```\n\n\n:::\n:::\n\n\nBad!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_double_c_x <-  with(imp_default_c_x, lm(y ~ x_obs + c_x)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_double_c_x\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate conf.low conf.high\n1 0.4602637  0.30023 0.6202974\n```\n\n\n:::\n:::\n\n\nEven worse!!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_default_c_y <- mice(\n  data, \n  m = 5, \n  formulas = list(x_obs ~ c_y),\n  print = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_imp_c_y <- with(imp_default_c_y, lm(y ~ x_obs)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_imp_c_y\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate  conf.low conf.high\n1 0.3405789 0.1126282 0.5685295\n```\n\n\n:::\n:::\n\n\nYIKES!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_double_c_y <-  with(imp_default_c_y, lm(y ~ x_obs + c_y)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_double_c_y\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate  conf.low conf.high\n1 0.5128878 0.3216547 0.7041208\n```\n\n\n:::\n:::\n\n\nBetter since we are conditioning on `c_y` (but still bad!)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_default_noise <- mice(\n  data, \n  m = 5, \n  formulas = list(x_obs ~ noise),\n  print = FALSE) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_imp_noise <-  with(imp_default_noise, lm(y ~ x_obs)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_imp_noise\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate  conf.low conf.high\n1 0.4076967 0.2352155 0.5801779\n```\n\n\n:::\n:::\n\n\nEEK!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_double_noise <-  with(imp_default_noise,lm(y ~ x_obs + noise)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_double_noise\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate  conf.low conf.high\n1 0.4124791 0.2497624 0.5751959\n```\n\n\n:::\n:::\n\n\nJust as bad..\n\nLet's put those in the original plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_rows(\n  mod_full_c_x,\n  mod_full_c_y,\n  mod_full_noise,\n  mod_cc_c_x,\n  mod_cc_c_y,\n  mod_cc_noise,\n  mod_imp_c_x,\n  mod_imp_c_y,\n  mod_imp_noise,\n  mod_double_c_x,\n  mod_double_c_y,\n  mod_double_noise\n) |>\n  mutate(\n    mod = factor(c(\"Full data with c_x\", \n                   \"Full data with c_y\", \n                   \"Full data with noise\",\n                   \"Complete case with c_x\",\n                   \"Complete case wtih c_y\",\n                   \"Complete case with noise\",\n                   \"Default Imputation with c_x\",\n                   \"Default Imputation with c_y\",\n                   \"Default Imputation with noise\",\n                   \"Two models with c_x\",\n                   \"Two models with c_y\",\n                   \"Two models with noise\" ),\n                 levels = c(\"Full data with c_x\", \n                            \"Complete case with c_x\",\n                            \"Default Imputation with c_x\",\n                            \"Two models with c_x\",\n                            \"Full data with c_y\", \n                            \"Complete case wtih c_y\",\n                            \"Default Imputation with c_y\",\n                            \"Two models with c_y\",\n                            \"Full data with noise\",\n                            \"Complete case with noise\",\n                            \"Default Imputation with noise\",\n                            \"Two models with noise\" )),\n    mod = fct_rev(mod),\n  ) -> to_plot\n\nggplot(to_plot, aes(x = estimate, xmin = conf.low, xmax = conf.high, y = mod)) +\n  geom_pointrange() + \n  geom_vline(xintercept = 1, lty = 2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\nAHH! This makes me so scared of imputation!!\n\n[Rebecca Andridge's tweet](https://twitter.com/rrandridge/status/1653029200838664193?s=20) finally helped me see why this is happening. The way the missing data is generated, larger values of `c_x` have a higher probability of missingness, and for particularly high values of `c_x` that probability is almost 1. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = x, y = y, color = factor(x_miss))) +\n  geom_point() + \n  geom_vline(xintercept = 2.31, lty = 2) +\n  labs(color = \"missing\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\nTake a look at the plot above. We have *no* non-missing `x` values that are greater than 2.3. The way predictive mean matching (the default `{mice}` method) works is it finds the observation(s) that have the closest predicted value to the observation that is missing a data point and gives you *that* non-missing data point's value. So here, we are essentially truncating our distribution at 2.3, since that is the highest value observed. Any value that would have been higher is going to be necessarily too small instead of the right value (this is different from the linear model method used in the first part of this post, which allows you to extrapolate). This is supposed to be a less biased approach, since it doesn't allow you to extrapolate beyond the bounds of your observed data, but it can actually induce bias when you have pockets of missingness with no observed `x`s (which I would argue might happen frequently!). Here is an example of one of the imputed datasets, notice nothing is above that 2.3 line!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(complete(imp_default_c_x), aes(x = x_obs, y = y, color = factor(x_miss))) + \n  geom_point() + \n  scale_x_continuous(limits = c(-2.8, 3.1)) +\n  geom_vline(xintercept = 2.31, lty = 2) +\n  labs(color = \"imputed\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n\n## What if we use `y` in the imputation models\n\nIncluding `y` in the imputation model [is definitely recommended](https://pubmed.ncbi.nlm.nih.gov/16980150/), as was hammered home for me by the wonderful Frank Harrell, but I'm not sure this recommendation has permeated through the field yet (although [this paper re-iterating this result](https://journals.sagepub.com/doi/10.1177/09622802231165001) just came out yesterday so maybe it is!).\n\nLet's see how that improves our imputation models:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_y_c_x <- mice(\n  data, \n  m = 5, \n  formulas = list(x_obs ~ c_x + y),\n  print = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_imp_c_x <- with(imp_y_c_x, lm(y ~ x_obs)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_imp_c_x\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  estimate  conf.low conf.high\n1 1.034138 0.9109341  1.157343\n```\n\n\n:::\n:::\n\n\nBeautiful!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_double_c_x <-  with(imp_y_c_x, lm(y ~ x_obs + c_x)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_double_c_x\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  estimate  conf.low conf.high\n1  1.08074 0.8772936  1.284186\n```\n\n\n:::\n:::\n\n\nA bit worse, but not bad!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_y_c_y <- mice(\n  data, \n  m = 5, \n  formulas = list(x_obs ~ c_y + y),\n  print = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_imp_c_y <- with(imp_y_c_y, lm(y ~ x_obs)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_imp_c_y\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate  conf.low conf.high\n1 0.9298631 0.8137157  1.046011\n```\n\n\n:::\n:::\n\n\nNot bad!! A bit biased but way better.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_double_c_y <-  with(imp_y_c_y, lm(y ~ x_obs + c_y)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_double_c_y\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  estimate  conf.low conf.high\n1  1.01812 0.9415964  1.094644\n```\n\n\n:::\n:::\n\n\nLove it, looks great after conditioning on `c_y`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_y_noise <- mice(\n  data, \n  m = 5, \n  formulas = list(x_obs ~ noise + y),\n  print = FALSE) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_imp_noise <-  with(imp_y_noise, lm(y ~ x_obs)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_imp_noise\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate  conf.low conf.high\n1 0.9671593 0.8580147  1.076304\n```\n\n\n:::\n:::\n\n\nOo lala, even does well when we don't have the right model (this makes sense because we are using `y`!)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_double_noise <-  with(imp_y_noise, lm(y ~ x_obs + noise)) |>\n  pool() |>\n  tidy(conf.int = TRUE) |>\n  filter(term == \"x_obs\") |>\n  select(estimate, conf.low, conf.high)\n\nmod_double_noise\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate  conf.low conf.high\n1 0.9697639 0.8612499  1.078278\n```\n\n\n:::\n:::\n\n\nLet's put those in the original plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_rows(\n  mod_full_c_x,\n  mod_full_c_y,\n  mod_full_noise,\n  mod_cc_c_x,\n  mod_cc_c_y,\n  mod_cc_noise,\n  mod_imp_c_x,\n  mod_imp_c_y,\n  mod_imp_noise,\n  mod_double_c_x,\n  mod_double_c_y,\n  mod_double_noise\n) |>\n  mutate(\n    mod = factor(c(\"Full data with c_x\", \n                   \"Full data with c_y\", \n                   \"Full data with noise\",\n                   \"Complete case with c_x\",\n                   \"Complete case wtih c_y\",\n                   \"Complete case with noise\",\n                   \"Imputation with c_x and y\",\n                   \"Imputation with c_y and y\",\n                   \"Imputation with noise and y\",\n                   \"Two models with c_x\",\n                   \"Two models with c_y\",\n                   \"Two models with noise\" ),\n                 levels = c(\"Full data with c_x\", \n                            \"Complete case with c_x\",\n                            \"Imputation with c_x and y\",\n                            \"Two models with c_x\",\n                            \"Full data with c_y\", \n                            \"Complete case wtih c_y\",\n                            \"Imputation with c_y and y\",\n                            \"Two models with c_y\",\n                            \"Full data with noise\",\n                            \"Complete case with noise\",\n                            \"Imputation with noise and y\",\n                            \"Two models with noise\" )),\n    mod = fct_rev(mod),\n  ) -> to_plot\n\nggplot(to_plot, aes(x = estimate, xmin = conf.low, xmax = conf.high, y = mod)) +\n  geom_pointrange() + \n  geom_vline(xintercept = 1, lty = 2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-39-1.png){width=672}\n:::\n:::\n\n\nPretty good! Maybe I'm feeling a little better about imputation. Maybe. But it had better include the outcome (which I'll admit feels *very* weird for my little causal brain).\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}